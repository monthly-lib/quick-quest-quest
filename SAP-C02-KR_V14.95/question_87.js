const question_87=`QUESTION NO: 87 한 회사가 AWS에서 데이터 집약적인 애플리케이션을 실행하고 있습니다. 이 애플리케이션은 수백 개의 Amazon EC2 인스턴스로 구성된 클러스터에서 실행됩니다. 공유 파일 시스템은 200TB의 데이터를 저장하는 여러 EC2 인스턴스에서도 실행됩니다. 애플리케이션은 공유 파일 시스템의 데이터를 읽고 수정하며 보고서를 생성합니다. 작업은 한 달에 한 번 실행되며 공유 파일 시스템에서 파일의 하위 집합을 읽고 완료하는 데 약 72시간이 걸립니다. 컴퓨트 인스턴스는 Auto Scaling 그룹에서 확장되지만 공유 파일 시스템을 호스팅하는 인스턴스는 계속 실행됩니다. 컴퓨팅 및 스토리지 인스턴스는 모두 동일한 AWS 리전에 있습니다. 솔루션 설계자는 공유 파일 시스템 인스턴스를 교체하여 비용을 줄여야 합니다. 파일 시스템은 72시간 실행 기간 동안 필요한 데이터에 대한 고성능 액세스를 제공해야 합니다. 이러한 요구 사항을 충족하면서 가장 큰 전체 비용 절감 효과를 제공하는 솔루션은 무엇입니까? A. 기존 공유 파일 시스템의 데이터를 S3 Intelligent-Tiering 스토리지 클래스를 사용하는 Amazon S3 버킷으로 마이그레이션합니다. 매월 작업이 실행되기 전에 Lustre용 Amazon FSx를 사용하여 지연 로딩을 사용하여 Amazon S3의 데이터로 새 파일 시스템을 생성합니다. 작업 기간 동안 새 파일 시스템을 공유 스토리지로 사용합니다. 작업이 완료되면 파일 시스템을 삭제합니다. B. 기존 공유 파일 시스템에서 다중 연결이 활성화된 대용량 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 데이터를 마이그레이션합니다. Auto Scaling 그룹 시작 템플릿의 사용자 데이터 스크립트를 사용하여 각 인스턴스에 EBS 볼륨을 연결합니다. 작업 기간 동안 EBS 볼륨을 공유 스토리지로 사용합니다. 작업이 완료되면 EBS 볼륨을 분리합니다. C. 기존 공유 파일 시스템의 데이터를 S3 Standard 스토리지 클래스를 사용하는 Amazon S3 버킷으로 마이그레이션합니다. 매월 작업이 실행되기 전에 Lustre용 Amazon FSx를 사용하여 일괄 로드를 사용하여 Amazon S3의 데이터로 새 파일 시스템을 생성합니다. 작업 기간 동안 새 파일 시스템을 공유 스토리지로 사용합니다. 작업이 완료되면 파일 시스템을 삭제합니다. D. 기존 공유 파일 시스템에서 Amazon S3 버킷으로 데이터를 마이그레이션합니다. 매월 작업이 실행되기 전에 AWS Storage Gateway를 사용하여 Amazon S3의 데이터로 파일 게이트웨이를 생성합니다. 파일 게이트웨이를 작업의 공유 스토리지로 사용합니다. 작업이 완료되면 파일 게이트웨이를 삭제합니다. Answer: A Explanation: https://aws.amazon.com/blogs/storage/new-enhancements-for-moving-data-betweenamazon-fsx-for-lustre-and-amazon-s3/`;