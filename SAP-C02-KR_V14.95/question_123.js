const question_123=`QUESTION NO: 123 회사는 Amazon RDS for MySQL 데이터베이스가 있는 Application Load Balancer(ALB) 뒤에 있는 두 개의 Linux Amazon EC2 인스턴스에서 중요한 상태 저장 웹 애플리케이션을 실행하고 있습니다. 회사는 Amazon Route 53에서 애플리케이션에 대한 DNS 레코드를 호스팅합니다. 솔루션 설계자는 솔루션을 추천해야 합니다. 애플리케이션의 복원력을 개선하기 위해 솔루션은 다음 목표를 충족해야 합니다. * 애플리케이션 계층 RPO는 2분입니다. 30분의 RTO * 5분의 데이터베이스 계층 RPO 30분의 RTO 회사는 기존 애플리케이션 아키텍처를 크게 변경하고 싶지 않습니다. 회사는 장애 조치 후 최적의 대기 시간을 보장해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? A. AWS Elastic Disaster Recovery를 사용하도록 EC2 인스턴스 구성 RDS DB 인스턴스에 대한 교차 리전 읽기 복제본 생성 두 번째 AWS 리전에서 ALB 생성 AWS Global Accelerator 엔드포인트 생성 및 엔드포인트를 ALB 업데이트 DNS 레코드와 연결 Global Accelerator 끝점을 가리키도록 B. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 EBS 볼륨의 스냅샷을 생성하도록 EC2 인스턴스 구성 RDS 자동 백업 구성 두 번째 AWS 리전에 대한 백업 복제 구성 두 번째 리전에 ALB 생성 AWS Global Accelerator 엔드포인트 생성 , 그리고 끝점을 ALB와 연결합니다. Global Accelerator 끝점을 가리키도록 DNS 레코드를 업데이트합니다. C. EC2 인스턴스 및 RDS DB 인스턴스에 대해 AWS Backup에서 백업 계획 생성 두 번째 AWS 리전에 대한 백업 복제 구성 두 번째 리전에 ALB 생성 ALB 앞에 Amazon CloudFront 배포 구성 다음을 가리키도록 DNS 레코드 업데이트 클라우드프론트 D. Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 EBS 볼륨의 스냅샷을 생성하도록 EC2 인스턴스 구성 RDS DB 인스턴스에 대한 교차 리전 읽기 복제본 생성 두 번째 AWS 리전에서 ALB 생성 AWS Global Accelerator 생성 끝점을 만들고 끝점을 ALB와 연결 Answer: B(A인것같음) Explanation: This option meets the RPO and RTO requirements for both the application and database tiers and uses tools like Amazon DLM and RDS automated backups to create and manage the backups. Additionally, it uses Global Accelerator to ensure low latency after failover by directing traffic to the closest healthy endpoint.
DRS에는 DLM 또는 백업에서 제공하는 것과 관련된 데이터뿐만 아니라 EC2 인스턴스도 포함됩니다. Q: AWS DRS에서는 어떤 운영 체제와 애플리케이션을 지원합니까? A: AWS DRS를 사용하면 지원되는 Windows 및 Linux 운영 체제 버전에서 실행되는 모든 애플리케이션과 데이터베이스를 복구할 수 있습니다. 여기에는 Oracle, MySQL, SQL Server 등의 중요 데이터베이스와 SAP 등의 엔터프라이즈 애플리케이션이 포함됩니다. AWS Elastic Disaster Recovery(DRS) 대 AWS DLM 대 AWS Backup EBS 스냅샷의 생성, 보존 및 삭제를 자동화하려면 DLM을 사용해야 합니다. EBS 볼륨을 포함하여 사용하는 AWS 서비스 전체의 백업을 한 곳에서 관리하고 모니터링하려면 AWS Backup을 사용해야 합니다.
다른 곳에서는 RTO 및 RPO 요구 사항을 충족할 수 없다는 점을 이해했습니다. 왜냐하면 뒤에서 복원하는 데는 데이터 크기에 따라 시간이 걸릴 수 있기 때문입니다.`;